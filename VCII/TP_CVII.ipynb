{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchsummary\n",
    "import torchmetrics\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta: cane, Cantidad de imágenes: 4863\n",
      "Carpeta: cavallo, Cantidad de imágenes: 2623\n",
      "Carpeta: elefante, Cantidad de imágenes: 1446\n",
      "Carpeta: farfalla, Cantidad de imágenes: 2112\n",
      "Carpeta: gallina, Cantidad de imágenes: 3098\n",
      "Carpeta: gatto, Cantidad de imágenes: 1668\n",
      "Carpeta: mucca, Cantidad de imágenes: 1866\n",
      "Carpeta: pecora, Cantidad de imágenes: 1820\n",
      "Carpeta: ragno, Cantidad de imágenes: 4821\n",
      "Carpeta: scoiattolo, Cantidad de imágenes: 1862\n"
     ]
    }
   ],
   "source": [
    "root_dir = './animales/raw-img/'\n",
    "\n",
    "images_per_folder = {}\n",
    "\n",
    "for folder in os.listdir(root_dir):\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        num_images = len(os.listdir(folder_path))\n",
    "        images_per_folder[folder] = num_images\n",
    "\n",
    "for folder, num_images in images_per_folder.items():\n",
    "    print(f\"Carpeta: {folder}, Cantidad de imágenes: {num_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './animales/raw-img/'\n",
    "\n",
    "# Obtener una lista de todas las carpetas en el directorio raíz\n",
    "folders = [folder for folder in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, folder))]\n",
    "\n",
    "# Crear listas para almacenar las rutas de las imágenes de entrenamiento y prueba\n",
    "train_dataset = []\n",
    "test_dataset = []\n",
    "\n",
    "# Iterar sobre cada carpeta\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "    # Obtener la lista de imágenes en la carpeta\n",
    "    images = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, img))]\n",
    "    # Dividir las imágenes en train y test\n",
    "    train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "    # Agregar las imágenes divididas a los conjuntos de entrenamiento y prueba\n",
    "    train_dataset.extend([(img_path, folder) for img_path in train_images])\n",
    "    test_dataset.extend([(img_path, folder) for img_path in test_images])\n",
    "\n",
    "# Crear directorios para el conjunto de entrenamiento y el conjunto de prueba\n",
    "train_dir = 'train_dataset'\n",
    "test_dir = 'test_dataset'\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Copiar imágenes al directorio de entrenamiento y prueba\n",
    "for dataset, dataset_dir in [(train_dataset, train_dir), (test_dataset, test_dir)]:\n",
    "    for img_path, label in dataset:\n",
    "        # Obtener la ruta de la carpeta de destino para esta imagen\n",
    "        target_folder = os.path.join(dataset_dir, label)\n",
    "        # Crear la carpeta si no existe\n",
    "        os.makedirs(target_folder, exist_ok=True)\n",
    "        # Copiar la imagen al directorio correspondiente\n",
    "        shutil.copy(img_path, target_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CANTIDAD_CLASES = 10\n",
    "ANCHO_IMAGENES = 150\n",
    "ALTO_IMAGENES = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(ANCHO_IMAGENES, ALTO_IMAGENES)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Crear conjuntos de datos ImageFolder\n",
    "train_set = torchvision.datasets.ImageFolder(train_dir, transform=data_transforms)\n",
    "test_set = torchvision.datasets.ImageFolder(test_dir, transform=data_transforms)\n",
    "\n",
    "# Crear DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 150, 150]             448\n",
      "         MaxPool2d-2           [-1, 16, 75, 75]               0\n",
      "            Conv2d-3           [-1, 32, 75, 75]           4,640\n",
      "         MaxPool2d-4           [-1, 32, 37, 37]               0\n",
      "            Conv2d-5           [-1, 64, 37, 37]          18,496\n",
      "         MaxPool2d-6           [-1, 64, 18, 18]               0\n",
      "            Conv2d-7          [-1, 128, 18, 18]          73,856\n",
      "         MaxPool2d-8            [-1, 128, 9, 9]               0\n",
      "            Linear-9                  [-1, 512]       5,308,928\n",
      "           Linear-10                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 5,411,498\n",
      "Trainable params: 5,411,498\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 6.37\n",
      "Params size (MB): 20.64\n",
      "Estimated Total Size (MB): 27.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class ConvModel(torch.nn.Module):\n",
    "    def __init__(self, output_units):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding='same')\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding='same')\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding='same')\n",
    "        self.pool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv4 = torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding='same')\n",
    "        self.pool4 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = torch.nn.Linear(in_features=10368, out_features=512)\n",
    "        self.fc2 = torch.nn.Linear(in_features=512, out_features=output_units)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = self.pool3(torch.relu(self.conv3(x)))\n",
    "        x = self.pool4(torch.relu(self.conv4(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "conv_model = ConvModel(CANTIDAD_CLASES)\n",
    "\n",
    "# Si hay una GPU disponible muevo el modelo allí para aprovechar ese recurso\n",
    "if torch.cuda.is_available():\n",
    "    conv_model.to(\"cuda\")\n",
    "\n",
    "torchsummary.summary(conv_model, (3, ANCHO_IMAGENES, ALTO_IMAGENES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, metric, data, epochs, tb_writer=None):\n",
    "\n",
    "    train_loader = data[\"train\"]\n",
    "    test_loader = data[\"test\"]\n",
    "\n",
    "    train_writer = tb_writer[\"train\"]\n",
    "    test_writer = tb_writer[\"test\"]\n",
    "\n",
    "    if tb_writer:\n",
    "        train_writer.add_graph(model, torch.zeros((1, 3, data[\"image_width\"], data[\"image_height\"])))\n",
    "        test_writer.add_graph(model, torch.zeros((1, 3, data[\"image_width\"], data[\"image_height\"])))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.to(\"cuda\")\n",
    "        metric.to(\"cuda\")\n",
    "\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Pongo el modelo en modo entrenamiento\n",
    "        model.train()\n",
    "\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_train_accuracy = 0.0\n",
    "\n",
    "        for train_data, train_target in train_loader:\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                train_data = train_data.to(\"cuda\")\n",
    "                train_target = train_target.to(\"cuda\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_data.float())\n",
    "            loss = criterion(output, train_target)\n",
    "            epoch_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            accuracy = metric(output, train_target)\n",
    "            epoch_train_accuracy += accuracy.item()\n",
    "\n",
    "        epoch_train_loss = epoch_train_loss / len(train_loader)\n",
    "        epoch_train_accuracy = epoch_train_accuracy / len(train_loader)\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        train_acc.append(epoch_train_accuracy)\n",
    "\n",
    "        # Pongo el modelo en modo testeo\n",
    "        model.eval()\n",
    "\n",
    "        epoch_test_loss = 0.0\n",
    "        epoch_test_accuracy = 0.0\n",
    "\n",
    "        for test_data, test_target in test_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                test_data = test_data.to(\"cuda\")\n",
    "                test_target = test_target.to(\"cuda\")\n",
    "\n",
    "            output = model(test_data.float())\n",
    "            epoch_test_loss += criterion(output, test_target).item()\n",
    "            epoch_test_accuracy += metric(output, test_target).item()\n",
    "\n",
    "        epoch_test_loss = epoch_test_loss / len(test_loader)\n",
    "        epoch_test_accuracy = epoch_test_accuracy / len(test_loader)\n",
    "        test_loss.append(epoch_test_loss)\n",
    "        test_acc.append(epoch_test_accuracy)\n",
    "\n",
    "        print(\"Epoch: {}/{} - Train loss {:.6f} - Train Accuracy {:.6f} - test Loss {:.6f} - test Accuracy {:.6f}\".format(\n",
    "        epoch+1, epochs, epoch_train_loss, epoch_train_accuracy, epoch_test_loss, epoch_test_accuracy))\n",
    "\n",
    "        if tb_writer:\n",
    "            train_writer.add_scalar(\"loss\", epoch_train_loss, epoch)\n",
    "            test_writer.add_scalar(\"loss\", epoch_test_loss, epoch)\n",
    "            train_writer.add_scalar(\"accuracy\", epoch_train_accuracy, epoch)\n",
    "            test_writer.add_scalar(\"accuracy\", epoch_test_accuracy, epoch)\n",
    "            train_writer.flush()\n",
    "            test_writer.flush()\n",
    "\n",
    "    history = {}\n",
    "    history[\"train_loss\"] = train_loss\n",
    "    history[\"train_acc\"] = train_acc\n",
    "    history[\"valid_loss\"] = test_loss\n",
    "    history[\"valid_acc\"] = test_acc\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20 - Train loss 1.966522 - Train Accuracy 0.296231 - test Loss 1.736423 - test Accuracy 0.387188\n",
      "Epoch: 2/20 - Train loss 1.653569 - Train Accuracy 0.428464 - test Loss 1.582197 - test Accuracy 0.442195\n",
      "Epoch: 3/20 - Train loss 1.514332 - Train Accuracy 0.481250 - test Loss 1.535006 - test Accuracy 0.466311\n",
      "Epoch: 4/20 - Train loss 1.417305 - Train Accuracy 0.515067 - test Loss 1.456741 - test Accuracy 0.491441\n",
      "Epoch: 5/20 - Train loss 1.337701 - Train Accuracy 0.546002 - test Loss 1.370114 - test Accuracy 0.531395\n",
      "Epoch: 6/20 - Train loss 1.264379 - Train Accuracy 0.570544 - test Loss 1.293256 - test Accuracy 0.555869\n",
      "Epoch: 7/20 - Train loss 1.192777 - Train Accuracy 0.597996 - test Loss 1.246918 - test Accuracy 0.573811\n",
      "Epoch: 8/20 - Train loss 1.120251 - Train Accuracy 0.622290 - test Loss 1.176899 - test Accuracy 0.598880\n",
      "Epoch: 9/20 - Train loss 1.054394 - Train Accuracy 0.646870 - test Loss 1.155194 - test Accuracy 0.607020\n",
      "Epoch: 10/20 - Train loss 0.988849 - Train Accuracy 0.669933 - test Loss 1.162711 - test Accuracy 0.605389\n",
      "Epoch: 11/20 - Train loss 0.926189 - Train Accuracy 0.690143 - test Loss 1.088713 - test Accuracy 0.634809\n",
      "Epoch: 12/20 - Train loss 0.870817 - Train Accuracy 0.708311 - test Loss 1.077011 - test Accuracy 0.644802\n",
      "Epoch: 13/20 - Train loss 0.813224 - Train Accuracy 0.727929 - test Loss 1.024488 - test Accuracy 0.660480\n",
      "Epoch: 14/20 - Train loss 0.757879 - Train Accuracy 0.746966 - test Loss 1.123781 - test Accuracy 0.630648\n",
      "Epoch: 15/20 - Train loss 0.707970 - Train Accuracy 0.767681 - test Loss 1.062493 - test Accuracy 0.652881\n",
      "Epoch: 16/20 - Train loss 0.661663 - Train Accuracy 0.782099 - test Loss 1.053466 - test Accuracy 0.663285\n",
      "Epoch: 17/20 - Train loss 0.602139 - Train Accuracy 0.804847 - test Loss 1.029548 - test Accuracy 0.668178\n",
      "Epoch: 18/20 - Train loss 0.551480 - Train Accuracy 0.819866 - test Loss 1.110766 - test Accuracy 0.651494\n",
      "Epoch: 19/20 - Train loss 0.500993 - Train Accuracy 0.836823 - test Loss 1.047032 - test Accuracy 0.676296\n",
      "Epoch: 20/20 - Train loss 0.450555 - Train Accuracy 0.853616 - test Loss 1.085825 - test Accuracy 0.678171\n"
     ]
    }
   ],
   "source": [
    "noaug_conv_model = ConvModel(CANTIDAD_CLASES)\n",
    "noaug_optimizer = torch.optim.Adam(noaug_conv_model.parameters(), lr=0.0001)\n",
    "noaug_loss = torch.nn.CrossEntropyLoss()\n",
    "noaug_metric = torchmetrics.Accuracy(task='multiclass', num_classes=CANTIDAD_CLASES)\n",
    "noaug_data = {\"train\": train_loader, \"test\": test_loader, \"image_width\": ANCHO_IMAGENES, \"image_height\": ALTO_IMAGENES}\n",
    "\n",
    "noaug_writer = {\"train\": SummaryWriter(log_dir=\"data_aug/noaug_train\"),\n",
    "                \"test\": SummaryWriter(log_dir=\"data_aug/noaug_test\")}\n",
    "\n",
    "history = train(noaug_conv_model,\n",
    "                noaug_optimizer,\n",
    "                noaug_loss,\n",
    "                noaug_metric,\n",
    "                noaug_data,\n",
    "                20,\n",
    "                noaug_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./model/naug_conv_model.pt\"\n",
    "torch.save(noaug_conv_model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "HISTORY_FILE_PATH = \"./output/history.json\"\n",
    "# Writing dictionary to JSON file\n",
    "with open(HISTORY_FILE_PATH, 'w') as json_file:\n",
    "    json.dump(history, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.9 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "92d9df9e3b037b8f3b306d779a99c536458a28b1ce0d1dc837ac3db5b7b2ca86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
