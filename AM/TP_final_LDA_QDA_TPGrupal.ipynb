{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpJ7s_SIVu_I"
      },
      "source": [
        "# Trabajo Práctico Final: Linear/Quadratic Discriminant Analysis (LDA/QDA)\n",
        "\n",
        "### Definición: Clasificador Bayesiano\n",
        "\n",
        "Sean $k$ poblaciones, $x \\in \\mathbb{R}^p$ puede pertenecer a cualquiera $g \\in \\mathcal{G}$ de ellas. Bajo un esquema bayesiano, se define entonces $\\pi_j \\doteq P(G = j)$ la probabilidad *a priori* de que $X$ pertenezca a la clase *j*, y se **asume conocida** la distribución condicional de cada observable dado su clase $f_j \\doteq f_{X|G=j}$.\n",
        "\n",
        "De esta manera dicha probabilidad *a posteriori* resulta\n",
        "$$\n",
        "P(G|_{X=x} = j) = \\frac{f_{X|G=j}(x) \\cdot p_G(j)}{f_X(x)} \\propto f_j(x) \\cdot \\pi_j\n",
        "$$\n",
        "\n",
        "La regla de decisión de Bayes es entonces\n",
        "$$\n",
        "H(x) \\doteq \\arg \\max_{g \\in \\mathcal{G}} \\{ P(G|_{X=x} = j) \\} = \\arg \\max_{g \\in \\mathcal{G}} \\{ f_j(x) \\cdot \\pi_j \\}\n",
        "$$\n",
        "\n",
        "es decir, se predice a $x$ como perteneciente a la población $j$ cuya probabilidad a posteriori es máxima.\n",
        "\n",
        "*Ojo, a no desesperar! $\\pi_j$ no es otra cosa que una constante prefijada, y $f_j$ es, en su esencia, un campo escalar de $x$ a simplemente evaluar.*\n",
        "\n",
        "### Distribución condicional\n",
        "\n",
        "Para los clasificadores de discriminante cuadrático y lineal (QDA/LDA) se asume que $X|_{G=j} \\sim \\mathcal{N}_p(\\mu_j, \\Sigma_j)$, es decir, se asume que cada población sigue una distribución normal.\n",
        "\n",
        "Por definición, se tiene entonces que para una clase $j$:\n",
        "$$\n",
        "f_j(x) = \\frac{1}{(2 \\pi)^\\frac{p}{2} \\cdot |\\Sigma_j|^\\frac{1}{2}} e^{- \\frac{1}{2}(x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j)}\n",
        "$$\n",
        "\n",
        "Aplicando logaritmo (que al ser una función estrictamente creciente no afecta el cálculo de máximos/mínimos), queda algo mucho más práctico de trabajar:\n",
        "\n",
        "$$\n",
        "\\log{f_j(x)} = -\\frac{1}{2}\\log |\\Sigma_j| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j) + C\n",
        "$$\n",
        "\n",
        "Observar que en este caso $C=-\\frac{p}{2} \\log(2\\pi)$, pero no se tiene en cuenta ya que al tener una constante aditiva en todas las clases, no afecta al cálculo del máximo.\n",
        "\n",
        "### LDA\n",
        "\n",
        "En el caso de LDA se hace una suposición extra, que es $X|_{G=j} \\sim \\mathcal{N}_p(\\mu_j, \\Sigma)$, es decir que las poblaciones no sólo siguen una distribución normal sino que son de igual matriz de covarianzas. Reemplazando arriba se obtiene entonces:\n",
        "\n",
        "$$\n",
        "\\log{f_j(x)} =  -\\frac{1}{2}\\log |\\Sigma| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j) + C\n",
        "$$\n",
        "\n",
        "Ahora, como $-\\frac{1}{2}\\log |\\Sigma|$ es común a todas las clases se puede incorporar a la constante aditiva y, distribuyendo y reagrupando términos sobre $(x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j)$ se obtiene finalmente:\n",
        "\n",
        "$$\n",
        "\\log{f_j(x)} =  \\mu_j^T \\Sigma^{-1} (x- \\frac{1}{2} \\mu_j) + C'\n",
        "$$\n",
        "\n",
        "### Entrenamiento/Ajuste\n",
        "\n",
        "Obsérvese que para ambos modelos, ajustarlos a los datos implica estimar los parámetros $(\\mu_j, \\Sigma_j) \\; \\forall j = 1, \\dots, k$ en el caso de QDA, y $(\\mu_j, \\Sigma)$ para LDA.\n",
        "\n",
        "Estos parámetros se estiman por máxima verosimilitud, de manera que los estimadores resultan:\n",
        "\n",
        "* $\\hat{\\mu}_j = \\bar{x}_j$ el promedio de los $x$ de la clase *j*\n",
        "* $\\hat{\\Sigma}_j = s^2_j$ la matriz de covarianzas estimada para cada clase *j*\n",
        "* $\\hat{\\pi}_j = f_{R_j} = \\frac{n_j}{n}$ la frecuencia relativa de la clase *j* en la muestra\n",
        "* $\\hat{\\Sigma} = \\frac{1}{n} \\sum_{j=1}^k n_j \\cdot s^2_j$ el promedio ponderado (por frecs. relativas) de las matrices de covarianzas de todas las clases. *Observar que se utiliza el estimador de MV y no el insesgado*\n",
        "\n",
        "Es importante notar que si bien todos los $\\mu, \\Sigma$ deben ser estimados, la distribución *a priori* puede no inferirse de los datos sino asumirse previamente, utilizándose como entrada del modelo.\n",
        "\n",
        "### Predicción\n",
        "\n",
        "Para estos modelos, al igual que para cualquier clasificador Bayesiano del tipo antes visto, la estimación de la clase es por método *plug-in* sobre la regla de decisión $H(x)$, es decir devolver la clase que maximiza $\\hat{f}_j(x) \\cdot \\hat{\\pi}_j$, o lo que es lo mismo $\\log\\hat{f}_j(x) + \\log\\hat{\\pi}_j$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TDWOgpJWKQa"
      },
      "source": [
        "## Estructura del código"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yEV8WbiWl6k"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "teF9O9JJmG7Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import det, inv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "sDBLvbTtlwzs"
      },
      "outputs": [],
      "source": [
        "class ClassEncoder:\n",
        "  def fit(self, y):\n",
        "    self.names = np.unique(y)\n",
        "    self.name_to_class = {name:idx for idx, name in enumerate(self.names)}\n",
        "    self.fmt = y.dtype\n",
        "    # Q1: why is there no need for class_to_name?\n",
        "    # Necesitamos convertirla a numeros para mejorar la eficiencia del algoritmo al tener que comparar las clases.\n",
        "\n",
        "  def _map_reshape(self, f, arr):\n",
        "    return np.array([f(elem) for elem in arr.flatten()]).reshape(arr.shape)\n",
        "    # Q2: why is reshaping necessary?\n",
        "\n",
        "  def transform(self, y):\n",
        "    return self._map_reshape(lambda name: self.name_to_class[name], y)\n",
        "\n",
        "  def fit_transform(self, y):\n",
        "    self.fit(y)\n",
        "    return self.transform(y)\n",
        "\n",
        "  def detransform(self, y_hat):\n",
        "    return self._map_reshape(lambda idx: self.names[idx], y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "m0KYC8_uSOu4"
      },
      "outputs": [],
      "source": [
        "class BaseBayesianClassifier:\n",
        "  def __init__(self):\n",
        "    self.encoder = ClassEncoder()\n",
        "\n",
        "  def _estimate_a_priori(self, y):\n",
        "    a_priori = np.bincount(y.flatten().astype(int)) / y.size\n",
        "    # Q3: what does bincount do?\n",
        "    return np.log(a_priori)\n",
        "\n",
        "  def _fit_params(self, X, y):\n",
        "    # estimate all needed parameters for given model\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def _predict_log_conditional(self, x, class_idx):\n",
        "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
        "    # this should depend on the model used\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def fit(self, X, y, a_priori=None):\n",
        "    # first encode the classes\n",
        "    y = self.encoder.fit_transform(y)\n",
        "\n",
        "    # if it's needed, estimate a priori probabilities\n",
        "    self.log_a_priori = self._estimate_a_priori(y) if a_priori is None else np.log(a_priori)\n",
        "\n",
        "    # check that a_priori has the correct number of classes\n",
        "    assert len(self.log_a_priori) == len(self.encoder.names), \"A priori probabilities do not match number of classes\"\n",
        "\n",
        "    # now that everything else is in place, estimate all needed parameters for given model\n",
        "    self._fit_params(X, y)\n",
        "    # Q4: why do we need to do this last, can't we do it first?\n",
        "\n",
        "  def predict(self, X):\n",
        "    # this is actually an individual prediction encased in a for-loop\n",
        "    m_obs = X.shape[1]\n",
        "    y_hat = np.empty(m_obs, dtype=self.encoder.fmt)\n",
        "\n",
        "    for i in range(m_obs):\n",
        "      encoded_y_hat_i = self._predict_one(X[:,i].reshape(-1,1))\n",
        "      y_hat[i] = self.encoder.names[encoded_y_hat_i]\n",
        "\n",
        "    # return prediction as a row vector (matching y)\n",
        "    return y_hat.reshape(1,-1)\n",
        "\n",
        "  def _predict_one(self, x):\n",
        "    # calculate all log posteriori probabilities (actually, +C)\n",
        "    log_posteriori = [ log_a_priori_i + self._predict_log_conditional(x, idx) for idx, log_a_priori_i\n",
        "                  in enumerate(self.log_a_priori) ]\n",
        "\n",
        "    # return the class that has maximum a posteriori probability\n",
        "    return np.argmax(log_posteriori)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "IRamFdiGDuSR"
      },
      "outputs": [],
      "source": [
        "class QDA(BaseBayesianClassifier):\n",
        "\n",
        "  def _fit_params(self, X, y):\n",
        "    # estimate each covariance matrix\n",
        "    self.inv_covs = [inv(np.cov(X[:,y.flatten()==idx], bias=True))\n",
        "                      for idx in range(len(self.log_a_priori))]\n",
        "    # Q5: why not just X[:,y==idx]?\n",
        "    # Q6: what does bias=True mean? why not use bias=False?\n",
        "    self.means = [X[:,y.flatten()==idx].mean(axis=1, keepdims=True)\n",
        "                  for idx in range(len(self.log_a_priori))]\n",
        "    # Q7: what does axis=1 mean? why not axis=0 instead?\n",
        "\n",
        "  def _predict_log_conditional(self, x, class_idx):\n",
        "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
        "    # this should depend on the model used\n",
        "    inv_cov = self.inv_covs[class_idx]\n",
        "    unbiased_x =  x - self.means[class_idx]\n",
        "    return 0.5*np.log(det(inv_cov)) -0.5 * unbiased_x.T @ inv_cov @ unbiased_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS_zoK-gWkRf"
      },
      "source": [
        "## Código para pruebas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "m05KrhUDINVs"
      },
      "outputs": [],
      "source": [
        "# hiperparámetros\n",
        "#rng_seed = 6543\n",
        "#rng_seed = 0\n",
        "rng_seed = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hkXcoldXOqs",
        "outputId": "b07a5027-be83-4c0a-a09e-e4f3a21e4c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: (150, 4), Y:(150, 1)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "def get_iris_dataset():\n",
        "  data = load_iris()\n",
        "  X_full = data.data\n",
        "  y_full = np.array([data.target_names[y] for y in data.target.reshape(-1,1)])\n",
        "  return X_full, y_full\n",
        "\n",
        "X_full, y_full = get_iris_dataset()\n",
        "\n",
        "print(f\"X: {X_full.shape}, Y:{y_full.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAk-UQCjKecT",
        "outputId": "ddf4e2f6-1baf-4a51-de72-5ce1d7c03db8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2]])"
            ]
          },
          "execution_count": 181,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# peek data matrix\n",
        "X_full[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdzMURX2KVdO",
        "outputId": "66a3cd6b-7dda-4618-b13f-628d113bf7d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['setosa'],\n",
              "       ['setosa'],\n",
              "       ['setosa'],\n",
              "       ['setosa'],\n",
              "       ['setosa']], dtype='<U10')"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# peek target vector\n",
        "y_full[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKP_QmWCIECs",
        "outputId": "36c28bcc-5d33-43e6-f231-3f3bf7b460cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4, 90) (1, 90) (4, 60) (1, 60)\n"
          ]
        }
      ],
      "source": [
        "# preparing data, train - test validation\n",
        "# 70-30 split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.4, random_state=rng_seed)\n",
        "\n",
        "# traspose everything because this model format assumes column vectors\n",
        "train_x = X_train.T\n",
        "train_y = y_train.T\n",
        "test_x = X_test.T\n",
        "test_y = y_test.T\n",
        "\n",
        "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "dGIf2TA5SpoT"
      },
      "outputs": [],
      "source": [
        "qda = QDA()\n",
        "\n",
        "qda.fit(train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0Q30DyLWpTL",
        "outputId": "c113c448-5230-44be-8f85-7a6d3f732d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train (apparent) error is 0.0222 while test error is 0.0167\n"
          ]
        }
      ],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  return (y_true == y_pred).mean()\n",
        "\n",
        "train_acc = accuracy(train_y, qda.predict(train_x))\n",
        "test_acc = accuracy(test_y, qda.predict(test_x))\n",
        "print(f\"Train (apparent) error is {1-train_acc:.4f} while test error is {1-test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Yb1V7_yXRfO"
      },
      "source": [
        "# Consigna\n",
        "\n",
        "## Implementación\n",
        "1. Entrenar un modelo QDA utilizando ahora una *a priori* uniforme ¿Se observan diferencias?¿Por qué?\n",
        "2. Implementar el modelo LDA, entrenarlo y testearlo contra los mismos sets que QDA ¿Se observan diferencias? ¿Podría decirse que alguno de los dos es notoriamente mejor que el otro?\n",
        "3. Utilizar otros 2 (dos) valores de *random seed* para obtener distintos splits de train y test, y repetir la comparación del punto anterior ¿Qué se observa?\n",
        "1. *(Opcional)* En `BaseBayesianClassifier._predict_one` se estima la posteriori de cada clase por separado, a pesar de que la cuenta es siempre la misma (cambiando valores de parámetros, pero no dimensiones). Aprovechando el *broadcasting* de NumPy, se puede reemplazar ese list comprehension por un cálculo *tensorizado* donde tanto medias como varianzas (o inversas) estén \"stackeadas\" sobre un tercer eje, permitiendo el cálculo en paralelo de todas las clases con un:\n",
        "`log_posteriori = self.tensor_log_a_priori + self._predict_log_conditionals(x)`. Implementar dicha modificación y mostrar su uso. *Ayuda: los métodos `np.stack` y la documentación del operador [`@`](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html) son de gran utilidad.*\n",
        "\n",
        "## Preguntas técnicas\n",
        "\n",
        "Responder las 7 preguntas que se encuentran distribuidas a lo largo del código.\n",
        "\n",
        "## Preguntas teóricas\n",
        "\n",
        "1. En LDA se menciona que la función a maximizar puede ser, mediante operaciones, convertida en:\n",
        "$$\n",
        "\\log{f_j(x)} =  \\mu_j^T \\Sigma^{-1} (x- \\frac{1}{2} \\mu_j) + C'\n",
        "$$\n",
        "Mostrar los pasos por los cuales se llega a dicha expresión.\n",
        "2. Explicar, utilizando las respectivas funciones a maximizar, por qué QDA y LDA son \"quadratic\" y \"linear\".\n",
        "3. La implementación de QDA estima la probabilidad condicional utilizando `0.5*np.log(det(inv_cov)) -0.5 * unbiased_x.T @ inv_cov @ unbiased_x` que no es *exactamente* lo descrito en el apartado teórico ¿Cuáles son las diferencias y por qué son expresiones equivalentes?\n",
        "\n",
        "El espíritu de esta componente práctica es la de establecer un mínimo de trabajo aceptable para su entrega; se invita al alumno a explorar otros aspectos que generen curiosidad, sin sentirse de ninguna manera limitado por la consigna.\n",
        "\n",
        "## Ejercicio teórico\n",
        "\n",
        "Sea una red neuronal de dos capas, la primera de 3 neuronas y la segunda de 1 con los parámetros inicializados con los siguientes valores:\n",
        "$$\n",
        "w^{(1)} =\n",
        "\\begin{pmatrix}\n",
        "0.1 & -0.5 \\\\\n",
        "-0.3 & -0.9 \\\\\n",
        "0.8 & 0.02\n",
        "\\end{pmatrix},\n",
        "b^{(1)} = \\begin{pmatrix}\n",
        "0.1 \\\\\n",
        "0.5 \\\\\n",
        "0.8\n",
        "\\end{pmatrix},\n",
        "w^{(2)} =\n",
        "\\begin{pmatrix}\n",
        "-0.4 & 0.2 & -0.5\n",
        "\\end{pmatrix},\n",
        "b^{(2)} = 0.7\n",
        "$$\n",
        "\n",
        "y donde cada capa calcula su salida vía\n",
        "\n",
        "$$\n",
        "y^{(i)} = \\sigma (w^{(i)} \\cdot x^{(i)}+b^{(i)})\n",
        "$$\n",
        "\n",
        "donde $\\sigma (z) = \\frac{1}{1+e^{-z}}$ es la función sigmoidea .\n",
        "\n",
        "\\\\\n",
        "Dada la observación $x=\\begin{pmatrix}\n",
        "1.8 \\\\\n",
        "-3.4\n",
        "\\end{pmatrix}$, $y=5$ y la función de costo $J(\\theta)=\\frac{1}{2}(\\hat{y}_\\theta-y)^2$, calcular las derivadas de J respecto de cada parámetro $w^{(1)}$, $w^{(2)}$, $b^{(1)}$, $b^{(2)}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resultados\n",
        "\n",
        "## Implementación\n",
        "1. Entrenar un modelo QDA utilizando ahora una *a priori* uniforme ¿Se observan diferencias?¿Por qué?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "1ChynN-GXSL5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train (apparent) error is 0.0222 while test error is 0.0167\n"
          ]
        }
      ],
      "source": [
        "# your code should start here\n",
        "import numpy as np\n",
        "\n",
        "apriori_uniforme = np.array([1/3,1/3,1/3])\n",
        "#apriori_nouniforme = np.array([0.9,0.05,0.05])\n",
        "\n",
        "qda = QDA()\n",
        "\n",
        "qda.fit(train_x, train_y)\n",
        "#qda.fit(train_x, train_y, apriori_nouniforme)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  return (y_true == y_pred).mean()\n",
        "\n",
        "train_acc = accuracy(train_y, qda.predict(train_x))\n",
        "test_acc = accuracy(test_y, qda.predict(test_x))\n",
        "print(f\"Train (apparent) error is {1-train_acc:.4f} while test error is {1-test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Implementar el modelo LDA, entrenarlo y testearlo contra los mismos sets que QDA ¿Se observan diferencias? ¿Podría decirse que alguno de los dos es notoriamente mejor que el otro?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class LDA(BaseBayesianClassifier):\n",
        "\n",
        "  def _fit_params(self, X, y):\n",
        "    # Combinacion lineal de lo que uno estima para QDA\n",
        "    self.inv_covs = [inv(np.cov(X[:,y.flatten()==idx], bias=True)) \n",
        "                      for idx in range(len(self.log_a_priori))]\n",
        "\n",
        "    cant = len(y) #número total\n",
        "    (elementos, frecuencia) = np.unique(y, return_counts=True) #se utiliza para obtener los valores únicos y sus frecuencias de un arreglo unidimensional\n",
        "    self.inv_cov_inbetween = np.zeros(self.inv_covs[0].shape) #creo una matriz de ceros del mismo tamaño que inv_covs\n",
        "    print(elementos)\n",
        "    print(frecuencia)\n",
        "    #asumo que las matrices de covariaza estan ordenadas por clase.\n",
        "    for i in range(len(frecuencia)):\n",
        "      self.inv_cov_inbetween = self.inv_cov_inbetween + np.multiply( self.inv_covs[i], (frecuencia[i])/cant) #pondera la matriz de covarianza de la clase actual por la frecuencia relativa de esa clase\n",
        "    \n",
        "    print(np.shape(self.inv_cov_inbetween))\n",
        "    self.inv_covs = [self.inv_cov_inbetween for i in range(len(elementos))]\n",
        "\n",
        "    self.means = [X[:,y.flatten()==idx].mean(axis=1, keepdims=True) \n",
        "      for idx in range(len(self.log_a_priori))] \n",
        "\n",
        "  def _predict_log_conditional(self, x, class_idx):\n",
        "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
        "    # this should depend on the model used\n",
        "    inv_cov = self.inv_covs[class_idx]\n",
        "    #unbiased_x =  x - self.means[class_idx]\n",
        "    unbiased_x =  x - 0.5*self.means[class_idx]\n",
        "    return  self.means[class_idx].T @ inv_cov @ unbiased_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2]\n",
            "[28 35 27]\n",
            "(4, 4)\n"
          ]
        }
      ],
      "source": [
        "lda1 = LDA()\n",
        "\n",
        "lda1.fit(train_x, train_y, a_priori=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Utilizar otros 2 (dos) valores de *random seed* para obtener distintos splits de train y test, y repetir la comparación del punto anterior ¿Qué se observa?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QDA Train (apparent) error is 0.02222222 while test error is 0.01666667\n",
            "LDA Train (apparent) error is 0.04444444 while test error is 0.01666667\n"
          ]
        }
      ],
      "source": [
        "##QDA\n",
        "def accuracy_qda(y_true, y_pred):\n",
        "  return (y_true == y_pred).mean()\n",
        "\n",
        "train_acc_qda = accuracy_qda(train_y, qda.predict(train_x))\n",
        "test_acc_qda = accuracy_qda(test_y, qda.predict(test_x))\n",
        "print(f\"QDA Train (apparent) error is {1-train_acc_qda:.8f} while test error is {1-test_acc_qda:.8f}\")\n",
        "\n",
        "\n",
        "##LDA\n",
        "def accuracy_lda(y_true, y_pred):\n",
        "  return (y_true == y_pred).mean()\n",
        "\n",
        "train_acc_lda = accuracy_lda(train_y, lda1.predict(train_x))\n",
        "test_acc_lda = accuracy_lda(test_y, lda1.predict(test_x))\n",
        "print(f\"LDA Train (apparent) error is {1-train_acc_lda:.8f} while test error is {1-test_acc_lda:.8f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Seed = 0\n",
        "\n",
        "QDA Train (apparent) error is 0.01111111 while test error is 0.03333333\n",
        "LDA Train (apparent) error is 0.01111111 while test error is 0.08333333\n",
        "\n",
        "Random Seed = 6543\n",
        "\n",
        "QDA Train (apparent) error is 0.01111111 while test error is 0.01666667\n",
        "LDA Train (apparent) error is 0.04444444 while test error is 0.01666667"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preguntas técnicas\n",
        "\n",
        "### Q1: why is there no need for class_to_name?\n",
        "El diccionario name_to_class es utilizado para mapear nombres de clases a índices de clase. No hay necesidad de un diccionario inverso class_to_name en este contexto específico.\n",
        "El diccionario inverso class_to_name podría ser útil si necesitaramos realizar operaciones como convertir índices de clases de nuevo a nombres de clases, por ejemplo, al interpretar los resultados de un modelo entrenado que devuelve índices de clases en lugar de nombres de clases directamente.\n",
        "### Q2: why is reshaping necessary?\n",
        "El método flatten() convierte el array multidimensional en un array unidimensional, se aplica la función f a cada elemento del array resultante, el reshaping es necesario para darle la dimensión original al array mapeado.\n",
        "### Q3: what does bincount do?\n",
        "np.bincount es una función de NumPy que se utiliza para contar las ocurrencias de números enteros no negativos en un array. Es muy útil para encontrar la frecuencia de cada número en un array de enteros no negativos.\n",
        "En este caso np.bincount se utiliza para determinar la frecuencia de cada una de las clases en y.\n",
        "### Q4: why do we need to do this last, can't we do it first?\n",
        "En términos generales, el enfoque de realizar preparaciones iniciales y luego ajustar los parámetros tiene sentido en la mayoría de los casos y sigue una estructura de trabajo común \n",
        "Es una buena práctica, en el desarrollo de algoritmos de aprendizaje automático, realizar primero las tareas de preprocesamiento y preparación de datos (como codificación de clases y estimación de probabilidades a priori), luego el ajuste de parámetros y por ultimo las tareas de validación o post-procesamiento. Esta estructura lógica facilita la lectura y comprensión del código.\n",
        "En el código dado, particular, hay una dependencia de las etiquetas de clase codificadas que se preparan en la primera sentencia: y = self.encoder.fit_transform(y).\n",
        "### Q5: why not just X[:,y==idx]?\n",
        "La función flatten() se utiliza para convertir una matriz multidimensional en un array unidimensional. En este contexto, se está utilizando para crear una máscara booleana que filtra las columnas de la matriz X basándose en las etiquetas de clase y, para cada índice idx. La idea detrás de X[:, y.flatten() == idx] es seleccionar las columnas correspondientes a la clase idx en la matriz X usando la máscara booleana creada a partir de y. Esto se hace porque y es una matriz 2D (o al menos es tratada como tal), pero la selección de columnas en X debe ser un array 2D, por lo que flatten() se utiliza para obtener una representación plana de y antes de usarlo como índice para seleccionar las columnas relevantes de X.\n",
        "No usamos simplemente X[:, y == idx] porque cuando y es un array 2D y se utiliza como índice en X, NumPy no hará la selección correcta de columnas, porque las dimensiones no coinciden. Usando flatten(), se convierte y en un array 1D que puede utilizarse para seleccionar las columnas correctamente.\n",
        "### Q6: what does bias=True mean? why not use bias=False?\n",
        "El parámetro bias en la función np.cov controla si se aplica un sesgo (bias) en la estimación de la matriz de covarianza. Cuando bias es True (el valor predeterminado), se divide por N (el número de observaciones) al calcular la covarianza. Cuando bias es False, se divide por N-1, lo que proporciona una estimación no sesgada de la matriz de covarianza (por ejemplo, se utiliza en el cálculo de la matriz de covarianza muestral).\n",
        "Se usa bias=true porque es un algoritmo de QDA, el cual es un modelo generativo que intenta modelar las distribuciones de probabilidad de las características en cada clase. En este contexto, aplicar un sesgo (dividir por N, el número de observaciones) puede ser apropiado, ya que se está construyendo un modelo basado en distribuciones de probabilidad. La estimación de la matriz de covarianza está vinculada a la forma en que las características se distribuyen en el espacio de características para cada clase.\n",
        "Además, en QDA se estima una matriz de covarianza diferente para cada clase. Estas matrices de covarianza capturan cómo las características están relacionadas dentro de cada clase. Aplicar un sesgo en la estimación (usando bias=True) puede ayudar a asegurar que las estimaciones de covarianza no sean demasiado sensibles a las fluctuaciones en los datos, lo que podría resultar en una mejor generalización del modelo.\n",
        "Por último, en algunos conjuntos de datos, las clases pueden tener diferentes tamaños y pueden variar en su cantidad de datos. Aplicar un sesgo puede ayudar a garantizar que la estimación de la matriz de covarianza no se vea influenciada en exceso por clases con un número significativamente menor de observaciones.\n",
        "### Q7: what does axis=1 mean? why not axis=0 instead?\n",
        "El parámetro axis=1 se refiere a la dirección a lo largo de la cual se realiza la operación de cálculo de la media. En este caso, axis=1 significa que la operación de cálculo de la media se realizará a lo largo de las filas, es decir, se calculará la media de las características para cada instancia.\n",
        "Si usáramos axis=0, la operación se realizaría a lo largo de las columnas, lo que daría como resultado las medias de las características a lo largo de las clases, en lugar de las medias de las instancias dentro de cada clase. Esto no sería adecuado en este contexto, ya que estás calculando las medias de las características para cada instancia dentro de cada clase.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preguntas teóricas\n",
        "\n",
        "1. En LDA se menciona que la función a maximizar puede ser, mediante operaciones, convertida en:\n",
        "$$\n",
        "\\log{f_j(x)} =  \\mu_j^T \\Sigma^{-1} (x- \\frac{1}{2} \\mu_j) + C'\n",
        "$$\n",
        "Mostrar los pasos por los cuales se llega a dicha expresión.\n",
        "\n",
        "Dado que para LDA $\\Sigma_j == \\Sigma $:\n",
        "$$\n",
        "\\log{f_j(x)} =  -\\frac{1}{2}\\log |\\Sigma| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j) + C\n",
        "$$\n",
        "\n",
        "Ahora, como $-\\frac{1}{2}\\log |\\Sigma|$ es común a todas las clases se puede incorporar a la constante aditiva. Luego, distribuyendo las matrices resultantes:\n",
        "$$\n",
        "\\log{f_j(x)} =  -\\frac{1}{2} x^T \\Sigma^{-1} x + \\frac{1}{2} x^T \\Sigma^{-1} \\mu_j + \\frac{1}{2} \\mu_j^T \\Sigma^{-1} x - \\frac{1}{2} \\mu_j^T \\Sigma^{-1} \\mu_j + C \n",
        "$$\n",
        "\n",
        "El primer término de la suma es independiente de la clase j, por lo que se puede incorporar a la constante aditiva.\n",
        "Ahora, si tomamos el segundo término de la suma, usando la propiedad de la transpuesta de un producto de matrices $ (AB)^T = B^T A^T $ y que $ (A^T)^T = A $ , resulta que \n",
        "$$\n",
        "x^T \\Sigma^{-1} \\mu_j = ( \\mu_j^T (\\Sigma^{-1})^T x )^T\n",
        "$$\n",
        "Dado que la matríz $\\Sigma$ es cuadrada y simétrica, luego $\\Sigma ^ -1$ es cuadrada y simétrica, entonces $ (\\Sigma^{-1})^T = (\\Sigma^{-1})$. Por lo tanto, la ecuación para el logaritmo de la probabilidad resulta:\n",
        "$$\n",
        "\\log{f_j(x)} =  \\frac{1}{2} [\\mu_j^T \\Sigma^{-1} x ]^T + \\frac{1}{2} \\mu_j^T \\Sigma^{-1} x - \\frac{1}{2} \\mu_j^T \\Sigma^{-1} \\mu_j + C \n",
        "$$\n",
        "\n",
        "Ahora, viendo las dimensiones de las matrices del primer término, tenemos que $\\mu_j \\epsilon ℝ^{(1xk)}$,  $\\Sigma \\epsilon ℝ^{(kxk)}$ y  $x \\epsilon ℝ^{(kx1)} $, donde k es la cantidad de features del dataset.\n",
        "\n",
        "Por lo tanto $ [\\mu_j^T \\Sigma^{-1} x ] $ es un escalar y la ecuación se puede reducir de la siguiente forma:\n",
        "$$\n",
        "\\log{f_j(x)} =  \\frac{1}{2} \\mu_j^T \\Sigma^{-1} x + \\frac{1}{2} \\mu_j^T \\Sigma^{-1} x - \\frac{1}{2} \\mu_j^T \\Sigma^{-1} \\mu_j + C = \\mu_j^T \\Sigma^{-1} x - \\frac{1}{2} \\mu_j^T \\Sigma^{-1} \\mu_j + C = \\mu_j^T \\Sigma^{-1} (x - \\frac{1}{2} \\mu_j^T) + C\n",
        "$$\n",
        "\n",
        "Lo que resulta que, para LDA:\n",
        "$$\n",
        "\\log{f_j(x)} = \\mu_j^T \\Sigma^{-1} (x - \\frac{1}{2} \\mu_j^T) + C\n",
        "$$\n",
        "\n",
        "2. Explicar, utilizando las respectivas funciones a maximizar, por qué QDA y LDA son \"quadratic\" y \"linear\".\n",
        "\n",
        "Tanto LDA (Análisis Discriminante Lineal) como QDA (Análisis Discriminante Cuadrático) son métodos utilizados en la clasificación de patrones. La razón por la que se llaman \"lineal\" y \"cuadrático\" se relaciona con la forma en que se modelan las distribuciones de las clases.\n",
        "\n",
        "Para entender esto, consideremos la expresión general que se busca maximizar en ambos métodos, que está relacionada con la función de densidad de probabilidad ${f_j(x)}$ de una observación x perteneciente a la clase j. Esta expresión implica la matriz de covarianza $\\Sigma_j$ y los vectores de medias $\\mu_j$ de la clase j.\n",
        "\n",
        "LDA (Análisis Discriminante Lineal):\n",
        "\n",
        "En el caso de LDA, asumimos que todas las clases comparten la misma matriz de covarianza $\\Sigma_j$, lo que significa que la variabilidad dentro de cada clase es similar. Esto hace que la expresión ${x^T \\Sigma^{-1} x}$ sea constante en todas las clases. Por lo tanto, podemos considerar esta parte como un término constante, que se suma a la constante aditiva \n",
        "C en la expresión de maximización.\n",
        "Dado que ${x^T \\Sigma^{-1} x}$ es constante y no depende de la clase, la expresión que estamos maximizando solo contiene términos lineales en x. Esto explica por qué se llama \"lineal\" al LDA. La función ${f_j(x)}$ en LDA es una combinación lineal de las variables x.\n",
        "\n",
        "QDA (Análisis Discriminante Cuadrático):\n",
        "\n",
        "En contraste, en el caso de QDA, permitimos que cada clase tenga su propia matriz de covarianza $\\Sigma_j$, lo que significa que la variabilidad puede ser diferente para cada clase. Como resultado, el término ${x^T \\Sigma^{-1} x}$ ya no es constante, sino que varía entre las clases. Además, debido a esta variabilidad, este término es cuadrático en x, lo que le da a QDA su naturaleza \"cuadrática\".\n",
        "La dependencia de la matriz de covarianza en la clase y el término cuadrático en x en la expresión de maximización son las razones por las cuales QDA se llama \"cuadrático\". La función \n",
        "${f_j(x)}$  en QDA es una función cuadrática de las variables x.\n",
        "\n",
        "En resumen, la diferencia clave entre LDA y QDA radica en cómo se modela la matriz de covarianza y cómo eso afecta la naturaleza lineal o cuadrática de la función de densidad de probabilidad.\n",
        "\n",
        "3. La implementación de QDA estima la probabilidad condicional utilizando `0.5*np.log(det(inv_cov)) -0.5 * unbiased_x.T @ inv_cov @ unbiased_x` que no es *exactamente* lo descrito en el apartado teórico ¿Cuáles son las diferencias y por qué son expresiones equivalentes?\n",
        "\n",
        "$$\n",
        "\\log{f_j(x)} = -\\frac{1}{2}\\log |\\Sigma_j| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j) + C\n",
        "$$\n",
        "\n",
        "Esta fórmula involucra la matriz de covarianza ${\\Sigma_j}$ y su inversa ${\\Sigma_j^{-1}}$. Sin embargo, en el código práctico se utiliza la inversa de la matriz de covarianza ${\\Sigma_j^{-1}}$ para calcular los términos relevantes.\n",
        "La razón por la cual estas dos formas de calcular el resultado son equivalentes radica en una propiedad de las determinantes y sus inversas. La propiedad es la siguiente:\n",
        "$$ |\\Sigma_j| = \\frac{1}{|\\Sigma_j^{-1}|} = (|\\Sigma_j^{-1}|)^{-1} $$ \n",
        "\n",
        "Esto significa que el primer término en la fórmula teórica $  -\\frac{1}{2}\\log |\\Sigma_j| = +\\frac{1}{2}\\log |\\Sigma_j^{-1}| $\n",
        "\n",
        "En la implementación práctica, se utiliza la inversa de la matriz de covarianza ${\\Sigma_j^{-1}}$ porque es necesaria para calcular el segundo término de la fórmula. Al usar ${\\Sigma_j^{-1}}$​, se evita la necesidad de guardar los valores tanto de ${\\Sigma_j}$ como de su inversa ${\\Sigma_j^{-1}}$ por separado, lo que simplifica el código y reduce la cantidad de cálculos necesarios.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicio teórico\n",
        "\n",
        "Sea una red neuronal de dos capas, la primera de 3 neuronas y la segunda de 1 con los parámetros inicializados con los siguientes valores:\n",
        "$$\n",
        "w^{(1)} =\n",
        "\\begin{pmatrix}\n",
        "0.1 & -0.5 \\\\\n",
        "-0.3 & -0.9 \\\\\n",
        "0.8 & 0.02\n",
        "\\end{pmatrix},\n",
        "b^{(1)} = \\begin{pmatrix}\n",
        "0.1 \\\\\n",
        "0.5 \\\\\n",
        "0.8\n",
        "\\end{pmatrix},\n",
        "w^{(2)} =\n",
        "\\begin{pmatrix}\n",
        "-0.4 & 0.2 & -0.5\n",
        "\\end{pmatrix},\n",
        "b^{(2)} = 0.7\n",
        "$$\n",
        "\n",
        "y donde cada capa calcula su salida vía\n",
        "\n",
        "$$\n",
        "y^{(i)} = \\sigma (w^{(i)} \\cdot x^{(i)}+b^{(i)})\n",
        "$$\n",
        "\n",
        "donde $\\sigma (z) = \\frac{1}{1+e^{-z}}$ es la función sigmoidea .\n",
        "\n",
        "\\\\\n",
        "Dada la observación $x=\\begin{pmatrix}\n",
        "1.8 \\\\\n",
        "-3.4\n",
        "\\end{pmatrix}$, $y=5$ y la función de costo $J(\\theta)=\\frac{1}{2}(\\hat{y}_\\theta-y)^2$, calcular las derivadas de J respecto de cada parámetro $w^{(1)}$, $w^{(2)}$, $b^{(1)}$, $b^{(2)}$.\n",
        "\n",
        "### Desarrollo\n",
        "\n",
        "1) Primera capa:\n",
        "\n",
        "$$\n",
        "z^{(1)} = \\sigma (w^{(1)} \\cdot x^{(1)}+b^{(1)})\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "y^{(1)} = \\sigma(z^{(1)})=\\sigma\n",
        "\\begin{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "0.1 & -0.5 \\\\\n",
        "-0.3 & -0.9 \\\\\n",
        "0.8 & 0.02\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "1.8 \\\\\n",
        "-3.4\n",
        "\\end{pmatrix}+\n",
        "\\begin{pmatrix}\n",
        "0.1 \\\\\n",
        "0.5 \\\\\n",
        "0.8\n",
        "\\end{pmatrix}\n",
        "\\end{pmatrix} =\n",
        "\\begin{pmatrix}\n",
        "\\sigma(\n",
        "0.1 \\cdot 1.8 + (-0.5)\\cdot(-3.4) + 0.1)\\\\\n",
        "\\sigma(\n",
        "0.3 \\cdot 1.8 + (-0.9)\\cdot(-3.4) + 0.5)\\\\\n",
        "\\sigma(\n",
        "0.8 \\cdot 1.8 + (0.02)\\cdot(-3.4) + 0.8)\n",
        "\\end{pmatrix} =\n",
        "\\begin{pmatrix}\n",
        "0.57 \\\\\n",
        "-2.61 \\\\\n",
        "0.64\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "2) Segunda capa:\n",
        "\n",
        "$$\n",
        "z^{(1)} = \\sigma (w^{(1)} \\cdot x^{(1)}+b^{(1)})\n",
        "$$\n",
        "$$\n",
        "z^{(2)} = \\sigma (w^{(2)} \\cdot y^{(1)}+b^{(2)})\n",
        "$$\n",
        "\n",
        "$$\n",
        "y^{(2)} = \\sigma(z^{(2)})=\\sigma\n",
        "\\begin{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "-0.4 & 0.2 & -0.5\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "y^{(2)}[1] \\\\\n",
        "y^{(2)}[2] \\\\\n",
        "y^{(2)}[3] \\\\\n",
        "\\end{pmatrix}+\n",
        "\\begin{pmatrix}\n",
        "0.7\n",
        "\\end{pmatrix}\n",
        "\\end{pmatrix} =\n",
        "\\begin{pmatrix}\n",
        "\\sigma(\n",
        "-0.4 \\cdot 0.57 + 0.6\\cdot(-2.61) + (-0.5)\\cdot(0.64) + 0.7)\\\\\n",
        "\\end{pmatrix} =\n",
        "0.24 \n",
        "$$\n",
        "\n",
        "3) Función de Costo:\n",
        "\n",
        "$$\n",
        "J(\\theta)=\\frac{1}{2}(\\hat{y}_\\theta-y)^2 = \\frac{1}{2}(y^{(2)}-y)^2\n",
        "\n",
        "$$\n",
        "Backpropagation:\n",
        "\n",
        "Derivada de la función de costo con respecto a la salida de la capa de salida:\n",
        "$$\n",
        "\\frac{∂J}{∂y(2)} = (y^{(2)}-y)\n",
        "\n",
        "$$\n",
        "Derivada de ${y(2)}$ con respecto a ${z(2)}$:\n",
        "$$\n",
        "\\frac{∂y(2)}{∂z(2)} = \\sigma' (z^{(2)}) = σ(z^{(2)})\\cdot(1−σ(z^{(2)}))\n",
        "\n",
        "$$\n",
        "Derivada de ${y(1)}$ con respecto a ${z(1)}$:\n",
        "$$\n",
        "\\frac{∂y(1)}{∂z(1)} = \\sigma' (z^{(1)}) = σ(z^{(1)})\\cdot(1−σ(z^{(1)}))\n",
        "\n",
        "$$\n",
        "Derivada de ${z(2)}$ con respecto a ${b(2)}$:\n",
        "$$\n",
        "\\frac{∂z(2)}{∂b(2)} = 1\n",
        "\n",
        "$$\n",
        "Derivada de ${z(1)}$ con respecto a ${b(1)}$:\n",
        "$$\n",
        "\\frac{∂z(1)}{∂b(1)} = 1\n",
        "\n",
        "$$\n",
        "Derivada de ${z(2)}$ con respecto a ${w(2)}$:\n",
        "$$\n",
        "\\frac{∂z(2)}{∂w(2)} = y^{(1)}\n",
        "\n",
        "$$\n",
        "Derivada de ${z(1)}$ con respecto a ${w(1)}$:\n",
        "$$\n",
        "\\frac{∂z(1)}{∂w(1)} = x\n",
        "\n",
        "$$\n",
        "Derivada de ${z(2)}$ con respecto a ${y(1)}$:\n",
        "$$\n",
        "\\frac{∂z(2)}{∂w(2)} = w^{(2)}\n",
        "\n",
        "$$\n",
        "Derivada de ${z(1)}$ con respecto a ${x}$:\n",
        "$$\n",
        "\\frac{∂z(1)}{∂x} = w^{(1)}\n",
        "\n",
        "$$\n",
        "Derivadas usando regla de la cadena:\n",
        "$$\n",
        "\\frac{∂J}{∂w(2)} = \\frac{∂J}{∂y(2)} \\cdot \\frac{∂y(2)}{∂z(2)} \\cdot \\frac{∂z(2)}{∂w(2)} = (y^{(2)}-y) * \\sigma' (z^{(2)}) \\cdot  (y^{(1)})^T\n",
        "$$\n",
        "$$\n",
        "\\frac{∂J}{∂b(2)} = \\frac{∂J}{∂y(2)} \\cdot \\frac{∂y(2)}{∂z(2)} \\cdot \\frac{∂z(2)}{∂b(2)} = (y^{(2)}-y) * \\sigma' (z^{(2)}) \n",
        "$$\n",
        "$$\n",
        "\\frac{∂J}{∂w(1)} = \\frac{∂J}{∂y(2)} \\cdot \\frac{∂y(2)}{∂z(2)} \\cdot \\frac{∂z(2)}{∂y(1)} \\cdot \\frac{∂y(1)}{∂z(1)} \\cdot \\frac{∂z(1)}{∂w(1)}= (y^{(2)}-y) * \\sigma' (z^{(2)}) \\cdot w^{(2)} * \\sigma' (z^{(1)}) \\cdot  x^T\n",
        "$$\n",
        "$$\n",
        "\\frac{∂J}{∂w(1)} = \\frac{∂J}{∂y(2)} \\cdot \\frac{∂y(2)}{∂z(2)} \\cdot \\frac{∂z(2)}{∂y(1)} \\cdot \\frac{∂y(1)}{∂z(1)} \\cdot \\frac{∂z(1)}{∂b(1)}= (y^{(2)}-y) * \\sigma' (z^{(2)}) \\cdot w^{(2)} * \\sigma' (z^{(1)})\n",
        "$$\n",
        "\n",
        "### Resultados\n",
        "\n",
        "$$\n",
        "\\frac{∂J}{∂w(2)} = (0.24 - 5) \\cdot \\frac{1}{1+e^{0.37}} \\cdot (1 - \\frac{1}{1+e^{0.37}}) \\cdot  (y^{(1)})^T = -0.87 \\begin{pmatrix}\n",
        "0.57 & -2.61 & 0.64 \n",
        "\\end{pmatrix} =\n",
        "\\begin{pmatrix}\n",
        "-0.49 & 2.27 & -0.55 \n",
        "\\end{pmatrix} \n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{∂J}{∂b(2)} = -0.87\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{∂J}{∂w(1)} = (-0.87) \\begin{pmatrix}\n",
        "-0.4 & 0.2 & -0.5 \n",
        "\\end{pmatrix} \\cdot\n",
        "\\begin{pmatrix}\n",
        "0.24\\\\\n",
        "-9.48\\\\\n",
        "0.22\\\\ \n",
        "\\end{pmatrix} \\cdot\n",
        "\\begin{pmatrix}\n",
        "1.8 & -3.4 \n",
        "\\end{pmatrix} =\n",
        "\\begin{pmatrix}\n",
        "0.0816\\\\\n",
        "1.64\\\\\n",
        "0.0957\\\\ \n",
        "\\end{pmatrix} \\cdot\n",
        "\\begin{pmatrix}\n",
        "1.8 & -3.4 \n",
        "\\end{pmatrix} = \n",
        "\\begin{pmatrix}\n",
        "0.149 & -0.277\\\\\n",
        "2.95 & -5.57\\\\\n",
        "0.17 & -0.32\\\\ \n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{∂J}{∂b(2)} = \\begin{pmatrix}\n",
        "0.0816\\\\\n",
        "1.64\\\\\n",
        "0.0957\\\\ \n",
        "\\end{pmatrix} \n",
        "$$\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
