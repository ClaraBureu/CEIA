# Procesamiento del Lenguaje Natural (NLP)

<img src="https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg" width="500" align="center">

Este repositorio contiene todos los trabajos realizados durante el cursado de la materia NLP, dentro de la Especializacion en IA de la UBA (Universidad Nacional de Buenos Aires).

A continuación se detalla el contenido de estos trabajos:

## [Desafío 1: Word2Vec](Desafío1/Desafio_1.ipynb)
En este desafío, se implementa el algoritmo Word2Vec para aprender representaciones vectoriales densas de palabras a partir de grandes corpus de texto. Estas representaciones son útiles para capturar similitudes semánticas y relaciones entre palabras en un espacio vectorial.

## [Desafío 2: Embedding con Gensim](Desafío2/Desafio_2.ipynb)
En este desafío, se utiliza la biblioteca Gensim para crear embeddings de palabras a partir de un corpus de texto. Se exploran diferentes técnicas de embedding y se aplican para tareas como búsqueda de palabras similares y análisis de analogías.

## [Desafío 3: Text Prediction](Desafío3/3b_modelo_lenguaje.ipynb)
En este desafío, se construye un modelo de predicción de texto utilizando modelos de lenguaje estadísticos y recurrentes. El objetivo es predecir la próxima palabra en una secuencia de texto dada una historia previa, lo que implica capturar la estructura y el contexto del lenguaje.

## [Desafío 4: Q&A Chatbot (Embeddings + LSTM)](Desafío4/6-bot_qa.ipynb)
En este desafío, se desarrolla un chatbot de preguntas y respuestas utilizando embeddings de palabras y redes neuronales recurrentes (LSTM). El chatbot es capaz de entender preguntas en lenguaje natural y generar respuestas relevantes basadas en el contexto y el conocimiento almacenado.

## [Desafío 5: Bert Sentiment Analysis](Desafío5/7d - bert sentiment analysis multicategorial.ipynb)
En este desafío, se entrena un modelo de BERT para realizar análisis de sentimientos. BERT (Bidirectional Encoder Representations from Transformers) es un modelo de lenguaje preentrenado desarrollado por Google que ha demostrado un rendimiento sobresaliente en una variedad de tareas de procesamiento del lenguaje natural (NLP).